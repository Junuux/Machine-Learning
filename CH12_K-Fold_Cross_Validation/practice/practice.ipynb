{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>[ Preview ]</h2>\n",
    "\n",
    "<h4>\n",
    "<ul>\n",
    "    <li>sklearn의 iris data를 사용함</li>\n",
    "    <li>Model : LogisticRegression, SVM, Decision Tree, Random Forest</li>\n",
    "    <li>train_test_split, KFold, StratifiedKFold, cross_val_score에 따라 train dataset, test dataset을 나누어 각 경우에 따른 score 확인</li>\n",
    "</ul>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>[ EXERCISE ]</h2>\n",
    "\n",
    "<h4>Use iris flower dataset from sklearn library and use cross_val_score against following models to measure the performance of each. In the end figure out the model with best performance,</h4>\n",
    "<ol>\n",
    "    <li>Logistic Regression</li>\n",
    "    <li>SVM</li>\n",
    "    <li>Decision Tree</li>\n",
    "    <li>Random Forest</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR',\n",
       " 'data',\n",
       " 'data_module',\n",
       " 'feature_names',\n",
       " 'filename',\n",
       " 'frame',\n",
       " 'target',\n",
       " 'target_names']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>1. train_test_split</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size =0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9555555555555556\n",
      "0.9555555555555556\n",
      "0.9555555555555556\n",
      "0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "lr_1 = LogisticRegression()\n",
    "svc_1 = SVC()\n",
    "dt_1 = DecisionTreeClassifier()\n",
    "rf_1 = RandomForestClassifier()\n",
    "\n",
    "print(get_score(lr_1, X_train, X_test, y_train, y_test))\n",
    "print(get_score(svc_1, X_train, X_test, y_train, y_test))\n",
    "print(get_score(dt_1, X_train, X_test, y_train, y_test))\n",
    "print(get_score(rf_1, X_train, X_test, y_train, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>2. K-Fold</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>아래 함수를 만들지 않고 numpy를 이용하면 편리함 => 가장 아래 코드로 설명해 둠</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_score(list):\n",
    "    score = 0\n",
    "    for i in range(len(list)):\n",
    "        score += list[i]\n",
    "    return score/len(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jack0\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jack0\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 0.8666666666666667, 0.9333333333333333, 0.8333333333333334] 0.9266666666666665\n",
      "[1.0, 1.0, 0.8333333333333334, 0.9333333333333333, 0.7] 0.8933333333333333\n",
      "[1.0, 1.0, 0.8333333333333334, 0.9333333333333333, 0.8] 0.9133333333333333\n",
      "[1.0, 1.0, 0.8666666666666667, 0.9333333333333333, 0.7333333333333333] 0.9266666666666665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jack0\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "lr_2 = LogisticRegression()\n",
    "svc_2 = SVC()\n",
    "dt_2 = DecisionTreeClassifier()\n",
    "rf_2 = RandomForestClassifier()\n",
    "\n",
    "lr_kf_score = []\n",
    "svc_kf_score = []\n",
    "dt_kf_score = []\n",
    "rf_kf_score = []\n",
    "\n",
    "for train_index, test_index in kf.split(iris.data, iris.target):\n",
    "    X_train, X_test, y_train, y_test = iris.data[train_index], iris.data[test_index], \\\n",
    "                                       iris.target[train_index], iris.target[test_index]\n",
    "    lr_kf_score.append(get_score(lr_2, X_train, X_test, y_train, y_test))\n",
    "    svc_kf_score.append(get_score(svc_2, X_train, X_test, y_train, y_test))\n",
    "    dt_kf_score.append(get_score(dt_2, X_train, X_test, y_train, y_test))\n",
    "    rf_kf_score.append(get_score(rf_2, X_train, X_test, y_train, y_test))\n",
    "    \n",
    "print(lr_kf_score, mean_score(lr_kf_score))\n",
    "print(svc_kf_score, mean_score(svc_kf_score))\n",
    "print(dt_kf_score, mean_score(dt_kf_score))\n",
    "print(rf_kf_score, mean_score(lr_kf_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>3. cross_val_score</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jack0\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression : 0.9733333333333334\n",
      "SVC : 0.9666666666666666\n",
      "DecisionTreeClassifier : 0.9600000000000002\n",
      "RandomForestClassifier : 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lr_3 = LogisticRegression()\n",
    "svc_3 = SVC()\n",
    "dt_3 = DecisionTreeClassifier()\n",
    "rf_3 = RandomForestClassifier()\n",
    "\n",
    "lr_cvs_score = cross_val_score(lr_3, iris.data, iris.target, cv=5)\n",
    "svc_cvs_score = cross_val_score(svc_3, iris.data, iris.target, cv=5)\n",
    "dt_cvs_score = cross_val_score(dt_3, iris.data, iris.target, cv=5)\n",
    "rf_cvs_score = cross_val_score(rf_3, iris.data, iris.target, cv=5)\n",
    "\n",
    "print('LogisticRegression :', lr_cvs_score.mean())\n",
    "print('SVC :', svc_cvs_score.mean())\n",
    "print('DecisionTreeClassifier :', dt_cvs_score.mean())\n",
    "print('RandomForestClassifier :', rf_cvs_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>4. StratifiedKFold</h4>\n",
    "<ul>\n",
    "    <li>3. cross_val_score와 결과가 동일하게 나옴</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jack0\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9666666666666667, 1.0, 0.9333333333333333, 0.9666666666666667, 1.0] 0.9733333333333334\n",
      "[0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 1.0] 0.9666666666666666\n",
      "[0.9666666666666667, 0.9666666666666667, 0.9, 0.9666666666666667, 1.0] 0.9600000000000002\n",
      "[0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 0.9333333333333333, 1.0] 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "lr_skf_score = []\n",
    "svm_skf_score = []\n",
    "dt_skf_score = []\n",
    "rf_skf_score = []\n",
    "\n",
    "lr_4 = LogisticRegression()\n",
    "svc_4 = SVC()\n",
    "dt_4 = DecisionTreeClassifier()\n",
    "rf_4 = RandomForestClassifier()\n",
    "\n",
    "for train_index, test_index in skf.split(iris.data,iris.target):\n",
    "    X_train, X_test, y_train, y_test = iris.data[train_index], iris.data[test_index], \\\n",
    "                                       iris.target[train_index], iris.target[test_index]\n",
    "    lr_skf_score.append(get_score(lr_4, X_train, X_test, y_train, y_test))  \n",
    "    svm_skf_score.append(get_score(svc_4, X_train, X_test, y_train, y_test))\n",
    "    dt_skf_score.append(get_score(dt_4, X_train, X_test, y_train, y_test))\n",
    "    rf_skf_score.append(get_score(rf_4, X_train, X_test, y_train, y_test))\n",
    "    \n",
    "print(lr_skf_score, mean_score(lr_skf_score))\n",
    "print(svm_skf_score, mean_score(svm_skf_score))\n",
    "print(dt_skf_score, mean_score(dt_skf_score))\n",
    "print(rf_skf_score, mean_score(rf_skf_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>array의 경우 평균을 구하기 위해 numpy를 사용하면 편리하다</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9666666666666667, 1.0, 0.9333333333333333, 0.9666666666666667, 1.0] 0.9733333333333334\n",
      "[0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 1.0] 0.9666666666666666\n",
      "[0.9666666666666667, 0.9666666666666667, 0.9, 0.9666666666666667, 1.0] 0.9600000000000002\n",
      "[0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 0.9333333333333333, 1.0] 0.96\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(lr_skf_score, np.average(lr_skf_score))\n",
    "print(svm_skf_score, np.average(svm_skf_score))\n",
    "print(dt_skf_score, np.average(dt_skf_score))\n",
    "print(rf_skf_score, np.average(rf_skf_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b686d4d7a26051da04b71843ba5dd418a448823625a8705a0a7386a397e85c74"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
